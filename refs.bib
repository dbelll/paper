%% This BibTeX bibliography file in UTF-8 format was created using Papers.
%% http://mekentosj.com/papers/

@article{Grounds:2008p3736,
author = {M Grounds and D Kudenko}, 
journal = {Adaptive Agents and Multi-Agent Systems III. Adaptation and Multi-Agent Learning},
title = {Parallel reinforcement learning with linear function approximation},
pages = {60--74},
year = {2008},
date-added = {2010-07-18 16:22:08 -0400},
date-modified = {2010-07-18 16:22:41 -0400},
pmid = {7727367007129731177related:aYAKBVofPWsJ},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2008/Grounds/Adaptive%20Agents%20and%20Multi-Agent%20Systems%20III.%20Adaptation%20and%20Multi-Agent%20Learning%202008%20Grounds.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p3736},
read = {Yes},
rating = {0}
}

@article{Juan:1997p4780,
author = {C Juan and R Sutton and A Ram}, 
journal = {Adaptive Behavior},
title = {Experiments with Reinforcement Learning in Problems with Continuous State and Action Spaces},
abstract = {Abstract A key element in the solution of reinforcement learning problems is the value function. The purpose of this function is to measure the long-term utility or value of any given state. The function is important because an agent can use this measure to decide what to },
number = {September},
pages = {163--217},
volume = {6},
year = {1997},
date-added = {2010-11-20 12:27:47 -0500},
date-modified = {2011-02-20 18:51:38 -0500},
pmid = {related:_mVvhnj1SdwJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.1168&rep=rep1&type=pdf},
local-url = {file://localhost/Users/dbelll/Documents/Papers/1997/Juan/Adaptive%20Behavior%201997%20Juan.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p4780},
read = {Yes},
rating = {0}
}

@article{Palmer:2007p4912,
author = {V Palmer}, 
journal = {Thesis Chapter},
title = {Accelerated Approximate Reinforcement Learning on the GPU},
pages = {1--31},
year = {2007},
month = {Feb},
date-added = {2011-02-14 13:57:37 -0500},
date-modified = {2011-02-14 18:13:00 -0500},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2007/Palmer/Thesis%20Chapter%202007%20Palmer.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p4912},
rating = {0}
}

@article{Howes:2007p4914,
author = {L Howes and D Thomas}, 
journal = {GPU Gems 3, Chapter 37},
title = {Efficient Random Number Generation and Application Using CUDA},
affiliation = {Imperial College London},
year = {2007},
month = {Feb},
date-added = {2011-02-19 08:17:31 -0500},
date-modified = {2011-02-19 08:22:02 -0500},
URL = {http://http.developer.nvidia.com/GPUGems3/gpugems3_ch37.html},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p4914},
rating = {3}
}

@article{Lagoudakis:2003p4913,
author = {M.G Lagoudakis and R Parr}, 
journal = {The Journal of Machine Learning Research},
title = {Least-squares policy iteration},
pages = {1107--1149},
volume = {4},
year = {2003},
date-added = {2011-02-14 18:36:02 -0500},
date-modified = {2011-02-14 18:36:44 -0500},
pmid = {9678231225196240380related:_F3qlwX8T4YJ},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2003/Lagoudakis/The%20Journal%20of%20Machine%20Learning%20Research%202003%20Lagoudakis-1.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p4913},
rating = {0}
}

@article{Sutton:1998p3536,
author = {R Sutton and A Barto}, 
journal = {The MIT Press},
title = {Reinforcement learning: an introduction‎},
abstract = {The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts.},
pages = {322},
year = {1998},
month = {Jan},
keywords = {Computers}, 
date-added = {2010-05-22 17:09:29 -0400},
date-modified = {2010-08-24 12:08:13 -0400},
pmid = {CAFR6IBF4xYC},
URL = {http://books.google.com/books?id=CAFR6IBF4xYC&printsec=frontcover},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p3536},
rating = {5}
}

@article{Whiteson:2010p4931,
author = {S Whiteson and M Taylor{\ldots}}, 
journal = {Autonomous Agents and Multi-Agent {\ldots}},
title = {Critical factors in the empirical performance of temporal difference and evolutionary methods for reinforcement learning},
abstract = {Page 1. Auton Agent Multi-Agent Syst (2010) 21:1--35 DOI 10.1007/s10458-009-9100-2 Critical factors in the empirical performance of temporal difference and evolutionary methods for reinforcement learning Shimon Whiteson · Matthew E. Taylor · Peter Stone ...},
year = {2010},
month = {Jan},
date-added = {2011-03-17 17:23:56 -0400},
date-modified = {2011-03-17 17:23:56 -0400},
pmid = {10137719226414645837related:TcIXq-xpsIwJ},
URL = {http://www.springerlink.com/index/85X6722235PGNT36.pdf},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2010/Whiteson/Autonomous%20Agents%20and%20Multi-Agent%20%E2%80%A6%202010%20Whiteson.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p4931},
rating = {0}
}

@article{Tesauro:1994p232,
author = {G Tesauro}, 
journal = {Neural computation},
title = {TD-Gammon, a self-teaching backgammon program, achieves master-level play},
abstract = {TD-Gammon is a neural network that is able to teach itself to play backgammon solely by playing against itself and learning from the results, based on the TD(X) reinforcement learning algorithm (Sutton 1988). Despite starting from random initial weights (and hence random initial },
year = {1994},
month = {Jan},
date-added = {2010-04-14 08:12:01 -0400},
date-modified = {2010-08-24 12:07:35 -0400},
pmid = {6209393827240626731related:K0ouf8kyLFYJ},
URL = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.1994.6.2.215},
local-url = {file://localhost/Users/dbelll/Documents/Papers/1994/Tesauro/Neural%20computation%201994%20Tesauro.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p232},
read = {Yes},
rating = {5}
}

@article{Busoniu:2008p4935,
author = {L Busoniu and R Babuska{\ldots}}, 
journal = {Systems},
title = {A comprehensive survey of multiagent reinforcement learning},
abstract = {Abstract---Multiagent systems are rapidly finding applications in a variety of domains, including robotics, distributed control, telecommunications, and economics. The complexity of many tasks arising in these domains makes them difficult to solve with prepro- grammed agent ...},
year = {2008},
month = {Jan},
date-added = {2011-03-17 17:31:26 -0400},
date-modified = {2011-03-17 17:31:26 -0400},
pmid = {13416539032818919176related:CKdVniofMboJ},
URL = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4445757},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2008/Busoniu/Systems%202008%20Busoniu.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p4935},
rating = {0}
}

@article{Kretchmar:2002p3812,
author = {R Kretchmar}, 
journal = {The 6th World Conference on Systemics},
title = {Parallel reinforcement learning},
abstract = {Here we investigate the problem of multiple rein- forcement learning agents attempting to learn the value function of a particular task in . Each agent is simultaneously engaging in a separate learn- ing experience on the same task. It seems intuitive that each agent's },
year = {2002},
month = {Jan},
date-added = {2010-07-26 13:17:09 -0400},
date-modified = {2010-08-24 12:10:13 -0400},
pmid = {15904780725692475801related:mSlhic0hudwJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.132.6788&rep=rep1&type=pdf},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2002/Kretchmar/The%206th%20World%20Conference%20on%20Systemics%202002%20Kretchmar.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p3812},
read = {Yes},
rating = {5}
}

@article{Brownlee:2005p3733,
author = {J Brownlee}, 
journal = {hdl.handle.net},
title = {The pole balancing problem: a benchmark control theory problem},
abstract = { Download Download PDF (12 pages) (Adobe Acrobat PDF , 69.2 kB) Title    : a benchmark control theory problem Author(s) , Jason Abstract -  is a pseudo-standard benchmark problem from the field of control },
year = {2005},
month = {Jan},
date-added = {2010-05-25 17:24:38 -0400},
date-modified = {2010-08-24 12:09:35 -0400},
pmid = {2252164613688126259related:M-uVnshLQR8J},
URL = {http://hdl.handle.net/1959.3/38692},
local-url = {file://localhost/Users/dbelll/Documents/Papers/2005/Brownlee/hdl.handle.net%202005%20Brownlee.pdf},
uri = {papers://E4AD91F7-7CF4-4AE9-99C6-61B046897D08/Paper/p3733},
read = {Yes},
rating = {5}
}

